{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab 사용 시! Local PC로 실습하는 경우 실행 x / 단, 작업경로를 2025_LGE_DNN으로 맞춰주기\n",
    "\n",
    "!git clone https://github.com/Im-JihyunKim/2025_LGE_DNN.git\n",
    "%cd /content/2025_LGE_DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch 기초 Tutorial: Tensor Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'pytorch tensor : {torch.tensor([1, 2, 3, 4, 5]).dtype}')           # 64비트 정수\n",
    "print(f'pytorch tensor : {torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0]).dtype}') # 32비트 부동 소수점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch 기본 정수 데이터 타입 torch.int64 | 텐서 타입 torch.LongTensor\n",
      "pytorch 기본 실수 데이터 타입 torch.float32 | 텐서 타입 torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4,5]  # type(a) -> list\n",
    "\n",
    "a_long = torch.LongTensor(a)    # list -> 64비트 정수 데이터 타입의 텐서\n",
    "a_float = torch.FloatTensor(a)  # list -> 32비트 부동 소수점 데이터 타입의 텐서\n",
    "\n",
    "print(f'pytorch 기본 정수 데이터 타입 {a_long.dtype} | 텐서 타입 {a_long.type()}')\n",
    "print(f'pytorch 기본 실수 데이터 타입 {a_float.dtype} | 텐서 타입 {a_float.type()}')\n",
    "# cf. 참고. 텐서 타입: 텐서가 특정 데이터 타입의 데이터를 저장하고 있다는 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatype 변경 방법\n",
    "- cf. [`print()` function을 이용할 때, `f-string`을 이용하면 문자열을 쉽게 포맷팅 가능](https://docs.python.org/ko/3/tutorial/inputoutput.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변경 전 data type : torch.int64\n",
      "변경 후 data type : torch.float32\n",
      "변경 후 data type : torch.float32\n"
     ]
    }
   ],
   "source": [
    "a = torch.LongTensor([1,2,3,4,5])  # 정수형 데이터를 담은 1차원 텐서\n",
    "\n",
    "print(f'변경 전 data type : {a.dtype}')\n",
    "print(f'변경 후 data type : {a.type(torch.FloatTensor).dtype}')  # Tensor.type(변경할 텐서 타입)\n",
    "print(f'변경 후 data type : {a.float().dtype}')                  # Tensor.변경데이터타입()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy to Tensor & Tensor to Numpy\n",
    "- numpy (Numerical Python)는 다차원 배열을 생성하고 조작하는데 편리한 기능을 제공해주는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.IntTensor\n",
      "torch.IntTensor\n",
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "# numpy to tensor\n",
    "a = np.array([1,2,3,4,5])   # numpy array\n",
    "\n",
    "print(torch.from_numpy(a).type())   # torch.from_numpy(numpyarray) -> numpyarray를 tensor로 변환\n",
    "print(torch.tensor(a).type())       # torch.tensor(numpyarray)     -> numpyarray를 tensor로 변환\n",
    "print(torch.LongTensor(a).type())   # torch.텐서타입(numpyarray)    -> numpyarray를 특정 텐서 타입으로 변환\n",
    "                                                                    # 32비트 정수형에서 64비트 정수형으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# tensor to numpy\n",
    "a = torch.LongTensor([1,2,3,4,5])  # Tensor\n",
    "\n",
    "print(type(a.numpy()))  # Tensor.numpy()  -> Tensor를 numpy array로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU & GPU\n",
    "- cf. CUDA(Compute Unified Device Architecture)는 NVIDIA에서 개발한 프로그래밍 모델로, NVIDIA의 GPU를 사용하여 CPU보다 높은 계산 성능을 달성할 수 있게끔 도와주는 tool\n",
    "- GPU 계산을 가능케 하여, 딥러닝 모델 학습 및 추론에 필요한 computing 성능 가속화 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GPU를 사용할 수 있는지 없는지 확인\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tensor의 위치 확인\n",
    "a = torch.FloatTensor([1,2,3,4,5])\n",
    "a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# CPU to GPU\n",
    "print(a.cuda().device)\n",
    "print(a.to('cuda:0').device)\n",
    "print(a.to(0).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 to cpu\n",
      "cuda:0 to cpu\n"
     ]
    }
   ],
   "source": [
    "# GPU to CPU\n",
    "a = torch.FloatTensor([1,2,3,4,5]).to(0)\n",
    "print(f'{a.device} to {a.cpu().device}')\n",
    "print(f'{a.device} to {a.to(\"cpu\").device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 같은 형태의 벡터여도, 동일한 디바이스 상에 있어야 연산 가능\u001b[39;00m\n",
      "\u001b[0;32m      2\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;32m----> 3\u001b[0m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m## error\u001b[39;00m\n",
      "\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "# 같은 형태의 벡터여도, 동일한 디바이스 상에 있어야 연산 가능\n",
    "a = torch.FloatTensor([1,2,3,4,5]).to(0)\n",
    "a + a.cpu()   ## 본 코드는 에러가 납니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Index를 활용한 데이터 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]]) \n",
      " Tensor a의 형태: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 2차원 tensor 생성\n",
    "a = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]])\n",
    "print(a, '\\n Tensor a의 형태:', a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4., 5., 6.])\n",
      "tensor([4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "# index를 활용한 i번째 행(row) 선택\n",
    "i=1            # note: 0부터 시작\n",
    "print(a[i])    # i번째 행을 추출\n",
    "print(a[i,:])  # a의 [행, 열] 에서 i번째 행을 선택 (cf. : 는 처음부터 끝까지 모두 다 선택하겠다는 의미)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4., 5., 6.])\n",
      "tensor([2., 5., 8.])\n"
     ]
    }
   ],
   "source": [
    "# index를 활용한 j번째 열(column) 선택\n",
    "j=1\n",
    "print(a[j])    # j번째 **행**을 추출\n",
    "print(a[:,j])  # a의 [행, 열] 에서 j번째 **열**을 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.)\n"
     ]
    }
   ],
   "source": [
    "# index를 활용한 i번째 row, j번째 column element 선택\n",
    "i, j = 2, 1\n",
    "print(a[i,j])  # a의 [행, 열] 에서 i번째 행과 j번째 열의 **원소**를 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "tensor([[2., 3.],\n",
      "        [5., 6.],\n",
      "        [8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# index를 활용한 i~j-1까지 row or column 선택\n",
    "i, j = 1, 3\n",
    "print(a[i:j, :])  # Case 1. a의 [행, 열] 에서 i번째부터 j번째까지의 **행**과 모든 열(:)의 값을 선택\n",
    "print(a[:, i:j])  # Case 2. a의 [행, 열] 에서 모든 행(:)과 i번째부터 j번째까지의 **열**의 값을 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 특정 조건을 만족하는 데이터 선택\n",
    "e.g. 클래스가 '5'인 데이터만을 선택하기, 데이터 값이 n 이상인 것만 선택하기 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 3, 3, 4, 3, 1, 4, 2, 2, 0, 0, 3, 1, 4, 4, 3, 3, 0, 0, 5, 5, 2, 0, 4,\n",
      "        1, 3, 5, 5, 5, 0, 1, 1])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False,  True,\n",
      "         True, False, False, False, False, False,  True,  True,  True, False,\n",
      "        False, False])\n",
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 생성\n",
    "x = torch.randn(size=(32,5))  ## 샘플 수 32개, 한 샘플의 차원(변수 개수)은 5인 데이터(2차원 텐서) 생성\n",
    "y = torch.randint(0,6, size=(32,))  ## 0에서 5까지의 값(class)를 가지는 출력 변수 32개 생성\n",
    "\"\"\"note: x와 y는 각 샘플이 서로 mapping되는 형태\"\"\"\n",
    "\n",
    "print(y)            # 원본 y 값\n",
    "print(y==5)         # 원본 y 값 중 y가 5인 데이터만을 고르겠다는 조건(condition)\n",
    "print((y==5).sum()) # 조건(condition)에 맞는 데이터의 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False,  True,\n",
      "         True, False, False, False, False, False,  True,  True,  True, False,\n",
      "        False, False])\n",
      "tensor([5, 5, 5, 5, 5])\n",
      "tensor([[ 0.1318, -1.6764,  0.1410,  0.3976, -0.6281],\n",
      "        [-0.5259, -0.7957, -0.5100,  0.9956, -0.4574],\n",
      "        [-0.3535,  0.2440,  0.4238,  0.4315, -0.2120],\n",
      "        [ 0.5055,  0.0238, -0.0222,  0.2393, -0.7092],\n",
      "        [-1.5513,  1.3847, -0.8311, -1.4887, -0.1280]])\n",
      "torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "condition = (y==5)  # y가 5인 데이터만을 고르겠다는 조건 (condition)\n",
    "print(condition)\n",
    "\n",
    "print(y[condition])        # y가 5인 데이터만을 condition을 통해 인덱싱하여 출력\n",
    "print(x[condition])        # y 값이 5를 가지는 x 데이터만을 condition을 통해 인덱싱하여 출력\n",
    "print(x[condition].shape)  # y가 5인 x 데이터의 형태 출력 (32개의 샘플 중 몇 개의 샘플이 해당 조건을 충족하는지 확인 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False,  True,\n",
      "         True, False, False, False, False, False,  True,  True,  True, False,\n",
      "        False, False])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False,  True,\n",
      "         True, False, False, False, False, False,  True,  True,  True, False,\n",
      "        False, False])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False,  True,\n",
      "         True, False, False, False, False, False,  True,  True,  True, False,\n",
      "        False, False])\n"
     ]
    }
   ],
   "source": [
    "# 다양한 방식으로 condition을 만들기\n",
    "print(y==5)\n",
    "print(torch.where(y==5, True, False))   # y가 5인 데이터의 인덱스를 찾고, True, False로 반환\n",
    "print(y.eq(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False,  True,  True,  True,  True, False,  True, False, False, False,\n",
      "        False,  True, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True, False, False,  True, False,  True,  True,  True,  True, False,\n",
      "        False, False])\n",
      "tensor([False,  True,  True,  True,  True, False,  True, False, False, False,\n",
      "        False,  True, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True, False, False,  True, False,  True,  True,  True,  True, False,\n",
      "        False, False])\n"
     ]
    }
   ],
   "source": [
    "# 두 개 이상의 condition 만들기\n",
    "print((y>=3) & (y<=5))       # 1st condition인 y>=3 과 2nd condition인 y<=5 을 \"모두\"(&, and) 만족하는 다중 조건 생성\n",
    "print(torch.mul(y>=3, y<=5)) # mul (곱하기) 메소드를 통해서도 생성 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 특정 조건을 만족하는 데이터 인덱스 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 5, 4, 1, 2, 0, 4, 1, 2, 3, 4, 0, 5, 0, 4, 3, 3, 0, 4, 0, 5, 4, 2, 5,\n",
      "        0, 2, 1, 5, 3, 4, 1, 2])\n",
      "tensor(5)\n",
      "tensor([False,  True, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False, False, False, False, False,\n",
      "         True, False, False,  True, False, False, False,  True, False, False,\n",
      "        False, False])\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 생성\n",
    "x = torch.randn(size=(32,5))  ## 샘플 수 32개, 한 샘플의 차원(변수 개수)은 5인 데이터(2차원 텐서) 생성\n",
    "y = torch.randint(0,6, size=(32,))  ## 0에서 5까지의 값(class)를 가지는 출력 변수 32개 생성\n",
    "\"\"\"note: x와 y는 각 샘플이 서로 mapping되는 형태\"\"\"\n",
    "\n",
    "print(y)  # 전체 y 값 출력\n",
    "print((y==5).sum())  # y 값이 5인 조건을 충족하는 데이터 개수 세기\n",
    "\n",
    "condition = (y==5)  # 조건(condition) 지정\n",
    "print(condition)    # 조건을 만족하는 데이터가 무엇인지 True/False 형태로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1],\n",
      "        [12],\n",
      "        [20],\n",
      "        [23],\n",
      "        [27]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.nonzero(condition))  # condition에서 True(1, non-zero)인 행의 index를 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 통계량 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(45.)\n",
      "tensor(5.)\n",
      "tensor(2.7386)\n",
      "tensor(9.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# sum, mean, max, min, std\n",
    "print(torch.sum(a)) # a.sum()\n",
    "print(torch.mean(a)) # a.mean()\n",
    "print(torch.std(a)) # a.std()\n",
    "print(torch.max(a)) # a.max()\n",
    "print(torch.min(a)) # a.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12., 15., 18.])\n",
      "tensor([4., 5., 6.])\n",
      "tensor([3., 3., 3.])\n",
      "torch.return_types.max(\n",
      "values=tensor([7., 8., 9.]),\n",
      "indices=tensor([2, 2, 2]))\n",
      "torch.return_types.min(\n",
      "values=tensor([1., 2., 3.]),\n",
      "indices=tensor([0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "# 특정 dimension을 기준으로 계산 -> dim=0 : 각 행의 모든 열에 대해 동작\n",
    "print(torch.sum(a, dim=0))\n",
    "print(torch.mean(a, dim=0))\n",
    "print(torch.std(a, dim=0))\n",
    "print(torch.max(a, dim=0)) # 최대값과 최대값 인덱스를 같이 반환\n",
    "print(torch.min(a, dim=0)) # 최소값과 최소값 인덱스를 같이 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6., 15., 24.])\n",
      "tensor([2., 5., 8.])\n",
      "tensor([1., 1., 1.])\n",
      "torch.return_types.max(\n",
      "values=tensor([3., 6., 9.]),\n",
      "indices=tensor([2, 2, 2]))\n",
      "torch.return_types.min(\n",
      "values=tensor([1., 4., 7.]),\n",
      "indices=tensor([0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "# 특정 dimension을 기준으로 계산 -> dim=1 : 각 열의 모든 행에 대해 동작\n",
    "print(torch.sum(a, dim=1))\n",
    "print(torch.mean(a, dim=1))\n",
    "print(torch.std(a, dim=1))\n",
    "print(torch.max(a, dim=1)) # 최대값과 최대값 인덱스를 같이 반환\n",
    "print(torch.min(a, dim=1)) # 최소값과 최소값 인덱스를 같이 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Element-wise 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.FloatTensor([1,2,3,4,5,6])\n",
    "b = torch.FloatTensor([4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상수항 더하기 : tensor([2., 3., 4., 5., 6., 7.])\n",
      "상수항 곱하기 : tensor([ 2.,  4.,  6.,  8., 10., 12.])\n"
     ]
    }
   ],
   "source": [
    "print(f'상수항 더하기 : {a + 1}')\n",
    "print(f'상수항 곱하기 : {a * 2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 텐서 간 element-wise 더하기 : tensor([ 5.,  7.,  9., 11., 13., 15.])\n",
      "두 텐서 간 element-wise 곱하기 : tensor([ 4., 10., 18., 28., 40., 54.])\n"
     ]
    }
   ],
   "source": [
    "print(f'두 텐서 간 element-wise 더하기 : {a + b}')\n",
    "print(f'두 텐서 간 element-wise 곱하기 : {a * b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "함수를 활용한 element-wise 더하기 : tensor([2., 3., 4., 5., 6., 7.])\n",
      "함수를 활용한 element-wise 더하기 : tensor([ 5.,  7.,  9., 11., 13., 15.])\n",
      "함수를 활용한 element-wise 곱하기 : tensor([ 2.,  4.,  6.,  8., 10., 12.])\n",
      "함수를 활용한 element-wise 곱하기 : tensor([ 4., 10., 18., 28., 40., 54.])\n"
     ]
    }
   ],
   "source": [
    "print(f'함수를 활용한 element-wise 더하기 : {torch.add(a,1)}')\n",
    "print(f'함수를 활용한 element-wise 더하기 : {torch.add(a,b)}')\n",
    "print(f'함수를 활용한 element-wise 곱하기 : {torch.mul(a,2)}')\n",
    "print(f'함수를 활용한 element-wise 곱하기 : {torch.mul(a,b)}')\n",
    "# 나누기 = torch.div\n",
    "# 제곱 = torch.pow\n",
    "# 지수 = torch.exp\n",
    "# 로그 = torch.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.,  2.,  3.],\n",
      "        [18.,  5.,  6.],\n",
      "        [24.,  8.,  9.]])\n"
     ]
    }
   ],
   "source": [
    "# 특정 dimension만 더하고 싶으면 해당 dimension의 data를 선택한 후 변경\n",
    "a = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]])\n",
    "\n",
    "b = torch.FloatTensor([[11,12,13],\n",
    "                       [14,15,16],\n",
    "                       [17,18,19]])\n",
    "\n",
    "a[:,0] = a[:,0] + b[:,0]  # a텐서의 0번째 열(column) 원소 = a텐서의 0번째 열(column) 원소 + b텐서의 0번째 열(column) 원소\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 벡터/행렬 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(40)\n",
      "tensor([[ 2,  3,  4,  5],\n",
      "        [ 4,  6,  8, 10],\n",
      "        [ 6,  9, 12, 15],\n",
      "        [ 8, 12, 16, 20]])\n"
     ]
    }
   ],
   "source": [
    "# 두 벡터 간 내적 외적\n",
    "a = torch.tensor([1,2,3,4])\n",
    "b = torch.tensor([2,3,4,5])\n",
    "\n",
    "c = torch.dot(a,b)     # 내적\n",
    "print(c) # tensor(40)\n",
    "\n",
    "d = torch.outer(a,b)   # 외적\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4., 7.],\n",
      "        [2., 5., 8.],\n",
      "        [3., 6., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# 벡터, 행렬 전치(transpose)\n",
    "a = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]])\n",
    "print(a.t()) # a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 2, 3, 4],\n",
      "        [9, 1, 2, 5],\n",
      "        [7, 1, 9, 7],\n",
      "        [2, 6, 1, 1],\n",
      "        [7, 3, 6, 7]])\n",
      "tensor([[7, 8, 6, 7],\n",
      "        [3, 4, 3, 4],\n",
      "        [4, 5, 2, 6],\n",
      "        [8, 6, 7, 4],\n",
      "        [8, 1, 7, 1],\n",
      "        [4, 3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "# 행렬곱\n",
    "a = torch.randint(1,10, size=(5,4))  # 1~9까지의 값을 가지는 4개 변수의 정수형 텐서를 5개 무작위 생성\n",
    "b = torch.randint(1,10, size=(6,4))  # 1~9까지의 값을 가지는 4개 변수의 정수형 텐서를 6개 무작위 생성\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[111,  54,  68, 105,  83,  66],\n",
      "        [118,  57,  75, 112,  92,  72],\n",
      "        [160,  80,  93, 153, 127, 102],\n",
      "        [ 75,  37,  46,  63,  30,  35],\n",
      "        [158,  79,  97, 144, 108,  96]])\n",
      "torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "# matmul은 행렬-벡터 간 연산 가능, mm은 행렬-행렬만 지원\n",
    "c = torch.matmul(a,b.t()) # torch.mm(a,b.T)\n",
    "\n",
    "print(c)\n",
    "print(c.shape) # c.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 결합 및 분해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.cat : 주어진 차원(axis)을 기준으로 텐서들을 이어 붙여(concatenation) 하나의 텐서로 만듦\n",
    "- 선택한 dimension(행/열)에 따라서 텐서들이 이어 붙여지며, dimension의 크기는 입력 텐서의 차원 크기 합이 됨. 다른 차원의 크기는 변경되지 않음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [11., 12., 13.],\n",
      "        [14., 15., 16.],\n",
      "        [17., 18., 19.]]) torch.Size([6, 3])\n",
      "tensor([[ 1.,  2.,  3., 11., 12., 13.],\n",
      "        [ 4.,  5.,  6., 14., 15., 16.],\n",
      "        [ 7.,  8.,  9., 17., 18., 19.]]) torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "a = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]])\n",
    "\n",
    "b = torch.FloatTensor([[11,12,13],\n",
    "                       [14,15,16],\n",
    "                       [17,18,19]])\n",
    "\n",
    "row_cat = torch.cat((a,b), dim=0)  # 행 단위로 결합 (아래로 쌓기)\n",
    "col_cat = torch.cat((a,b), dim=1)  # 열 단위로 결합 (옆으로 쌓기)\n",
    "\n",
    "print(row_cat, row_cat.shape)  # 6, 3\n",
    "print(col_cat, col_cat.shape)  # 3, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.stack : 주어진 차원(axis)을 기준으로 각각의 텐서들을 쌓아올려(stack) 새로운 차원을 추가하여 하나의 텐서로 만듦\n",
    "- 모든 입력 텐서가 동일한 크기를 가져야 하며, 결과 텐서의 크기는 입력 텐서 차원에서 1을 추가한 것과 같음\n",
    "- 즉, 새로운 차원이 추가되는 것이며, 해당 차원의 크기는 입력된 텐서의 개수와 같게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.],\n",
      "         [ 7.,  8.,  9.]],\n",
      "\n",
      "        [[11., 12., 13.],\n",
      "         [14., 15., 16.],\n",
      "         [17., 18., 19.]]]) torch.Size([2, 3, 3])\n",
      "tensor([[[ 1.,  2.,  3.],\n",
      "         [11., 12., 13.]],\n",
      "\n",
      "        [[ 4.,  5.,  6.],\n",
      "         [14., 15., 16.]],\n",
      "\n",
      "        [[ 7.,  8.,  9.],\n",
      "         [17., 18., 19.]]]) torch.Size([3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "stack_dim0 = torch.stack((a,b), dim=0)\n",
    "print(stack_dim0, stack_dim0.shape)  # 2, 3, 3 -> (3,3) 텐서가 2개\n",
    "\n",
    "stack_dim1 = torch.stack((a,b),dim=1)\n",
    "print(stack_dim1, stack_dim1.shape)  # 3, 2, 3 -> (2,3) 텐서가 3개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.chunk -> tensor 쪼개기\n",
    "- 텐서를 특정 차원을 기준으로, 특정 수의 조각만큼 균등하게 나눔\n",
    "- `chunks` 인자의 수만큼 균등하게 나누어 반환됨. 다만 완벽하게 균등하지 않을 경우 마지막 조각이 다른 조각보다 작을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1., 2., 3.]]), tensor([[4., 5., 6.]]), tensor([[-1., -2., -3.]]), tensor([[-4., -5., -6.]]))\n"
     ]
    }
   ],
   "source": [
    "# 하나의 텐서를 n개의 텐서로 분해하기\n",
    "a = torch.FloatTensor([\n",
    "    [ 1.,  2.,  3.],\n",
    "    [ 4.,  5.,  6.],\n",
    "    [-1., -2., -3.],\n",
    "    [-4., -5., -6.]\n",
    "])\n",
    "\n",
    "print(torch.chunk(a,chunks=4,dim=0))  # 텐서 a를 행(axis=0) 기준으로 4개로 분할(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.split -> tensor 분리하기\n",
    "- 텐서를 지정된 크기로 나눔\n",
    "- 분리 방식을 `torch.chunk`보다 세밀하게 제어 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1., 2., 3.]]), tensor([[4., 5., 6.]]), tensor([[-1., -2., -3.]]), tensor([[-4., -5., -6.]]))\n"
     ]
    }
   ],
   "source": [
    "# 하나의 텐서를 n개의 row를 가지는 텐서로 분리하기\n",
    "print(torch.split(a, split_size_or_sections=1, dim=0))  # 텐서 a를 행(axis=0) 기준으로 1개씩 분리\n",
    "                                                        # `split_size_or_sections` 인자가 리스트나 튜플로 입력될 경우, 지정된 크기의 목록에 따라 텐서를 나눔 -> 조각 크기를 더 정확하고 유연하게 지정 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor 차원 조작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor.unsqueeze -> 차원 늘리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# 데이터 생성\n",
    "a = torch.randn(size=(10,3))\n",
    "b = torch.randn(size=(3,))\n",
    "\n",
    "print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[56], line 2\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 차원의 개수가 다르면 에러 발생\u001b[39;00m\n",
      "\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 1"
     ]
    }
   ],
   "source": [
    "# 텐서를 병합하고자 할 때 차원이 다르면 에러 발생 (2차원과 1차원 텐서를 병합하지 못함)\n",
    "print(torch.cat((a,b), dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(b.unsqueeze(dim=0))  # unsqueeze -> 차원을 **늘리는** 메소드 (dim은 어떤 데이터 차원을 기준으로 늘릴 것인지를 결정해주는 인자)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.cat((a,b.unsqueeze(dim=0)), dim=0).shape  # 둘 다 2차원이기 때문에 병합 가능, dim=0으로 cat 하였기 때문에 맨 처음 차원에서 10+1=11로 늘어남."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor.squeeze -> 차원 줄이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성\n",
    "a = torch.randn(size=(1,10,3))\n",
    "b = torch.randn(size=(5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# squeeze()는 차원을 **줄여주는** 메소드. dim 인자로 어떤 차원을 기준으로 축소할 것인지를 결정\n",
    "torch.cat((a.squeeze(dim=0), b),dim=0).shape  # a를 10, 3 으로 줄였기에 2차원 텐서 간의 cat 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor.permute -> 차원 재배열\n",
    "- 텐서의 형태(shape)를 원하는 순서로 자유롭게 변경\n",
    "- 실제 데이터는 변경하지 않고 차원 순서만 변경하기 때문에 데이터 구조를 유연하게 조작 가능\n",
    "- CNN, LSTM 등에서 모델에 텐서 형태의 데이터를 입력할 때, 각각 요구하는 형태(shape)가 다른 경우가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32, 3, 128]) -> torch.Size([128, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# 차원을 여러 개로 변경\n",
    "images = torch.randn(size=(32,32,3,128))  # width=32, height=3, channel=3 이미지가 128개 있는 상황이라 가정\n",
    "print(f'{images.shape} -> {images.permute(3,2,0,1).shape}')  # 차원 순서를 교환 (cf. transpose() 함수도 유사한 방식으로 작동하나, 딱 두 개의 차원만 교환 가능. permute()는 모든 차원을 맞교환)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.reshape, torch.view -> 텐서 형태 변경\n",
    "- `reshape(input, shape)` : `input`은 형태를 변경할 원본 텐서, `shape`은 원하는 새로운 형태를 나타내는 정수의 튜플\n",
    "    - 원본 데이터를 자동으로 복사하여 요구되는 형태로 변경할 수 있음\n",
    "- `input.view(shape)` : `input`은 형태를 변경할 원본 텐서, `shape`은 원하는 새로운 형태를 나타내는 정수의 튜플\n",
    "    - 원본 데이터의 형태를 변경하기에 메모리 사용 측면에서 효율적일 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1024])\n",
      "torch.Size([3, 1024])\n"
     ]
    }
   ],
   "source": [
    "# 차원 재배열\n",
    "image = torch.randn(size=(3,32,32))\n",
    "\n",
    "print(image.reshape(3, 32*32).shape)\n",
    "print(image.view(3, 32*32).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch AutoGrad (자동 미분)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 경사 하강법: 1차 미분계수를 이용하여 함수의 최소값을 찾아내는 알고리즘\n",
    "- 이 경사 하강법을 이용해서 Cost function (Loss function)을 최소화하는 모델의 파라미터를 찾을 수 있음 (gradient에 따라 파라미터를 반복적으로 업데이트하며 최적화하는 것)\n",
    "    - 모델의 파라미터에 대해 Cost function의 1차 미분 값(gradient)을 구함. 이는 Cost function이 증가하는 방향을 가리킴\n",
    "    - 파라미터를 gradient의 반대 방향으로 계속 이동시켜 극값에 이를 때까지, 즉 cost(loss)를 최소화 시킬 수 있는 파라미터를 찾아낼 때까지 최적화\n",
    "    - cf. 이때 얼마나 이동할 것인지를 결정하는 또 다른 요인으로 학습률(`learning rate`)이 있음\n",
    "- PyTorch에서는 경사 하강법을 직접 구현할 필요 없이, 미분 계산을 자동화하여 손쉽게 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Image('./images/GD.PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function 정의\n",
    "\n",
    "def f(w: torch.tensor):\n",
    "    loss = w**3 + 2*w**2 + 7\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(39.)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(3.0, requires_grad=True)  # w는 신경망의 파라미터 -> 파라미터에 대한 오류의 기울기를 저장하기 위해 requires_grad=True 옵션 넣어주기\n",
    "\n",
    "f_w = f(w)\n",
    "f_w.backward()   # 기울기 계산 후 .grad 속성에 해당 기울기 값들을 저장\n",
    "print(w.grad)    # f_w를 w로 미분한 값\n",
    "\n",
    "print(w.grad == 3*w**2 + 4*w)  # backward로 수집한 기울기들이 올바른지 직접 확인! (cf. f'(x)=3x**2 + 4x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(size=(10,20))        # 입력 변수가 20개인 관측치 10 개\n",
    "y = torch.randn(size=(10,1))         # x에 해당하는 출력 변수\n",
    "\n",
    "w1 = torch.randn(size=(20,10), requires_grad=True) # linear layer1\n",
    "w2 = torch.randn(size=(10,1), requires_grad=True)  # linear layer2\n",
    "\n",
    "y_pred = torch.matmul((torch.matmul(x,w1)),w2) # forward\n",
    "\n",
    "def mse_loss_function(y_pred, y_true):\n",
    "    return (y_true-y_pred)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE loss:  tensor([[ 57.6675],\n",
      "        [ 95.5263],\n",
      "        [118.2916],\n",
      "        [ 29.6986],\n",
      "        [  0.4165],\n",
      "        [ 38.2602],\n",
      "        [181.1183],\n",
      "        [ 31.1537],\n",
      "        [ 67.5621],\n",
      "        [ 80.1242]], grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m loss \u001b[38;5;241m=\u001b[39m mse_loss_function(y_pred, y)       \u001b[38;5;66;03m# MSE Loss 계산\u001b[39;00m\n",
      "\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE loss: \u001b[39m\u001b[38;5;124m\"\u001b[39m, loss)  \u001b[38;5;66;03m# MSE loss가 관측치마다 계산됨 -> [10, 1] 형태의 텐서.\u001b[39;00m\n",
      "\u001b[1;32m----> 4\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# backward --> error!!! gradient는 하나의 scalar outputs에 대해서만 계산 가능하기 때문! (grad can be implicitly created only for scalar outputs)\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JihyunKim\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n",
      "\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n",
      "\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n",
      "\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n",
      "\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n",
      "\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JihyunKim\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py:166\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n",
      "\u001b[0;32m    162\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (inputs,) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m \\\n",
      "\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mtuple\u001b[39m(inputs) \u001b[38;5;28;01mif\u001b[39;00m inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n",
      "\u001b[0;32m    165\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n",
      "\u001b[1;32m--> 166\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JihyunKim\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py:67\u001b[0m, in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads, is_grads_batched)\u001b[0m\n",
      "\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mrequires_grad:\n",
      "\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;32m---> 67\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m     68\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mones_like(out, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format))\n",
      "\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\n",
      "\u001b[1;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "loss = mse_loss_function(y_pred, y)       # MSE Loss 계산\n",
    "print(\"MSE loss: \", loss)  # MSE loss가 관측치마다 계산됨 -> [10, 1] 형태의 텐서.\n",
    "\n",
    "loss.backward() # backward --> error!!! gradient는 하나의 scalar outputs에 대해서만 계산 가능하기 때문! \n",
    "                                     # (grad can be implicitly created only for scalar outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE loss:  tensor(69.9819, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 12.4869,  -8.0002,   3.7135,   1.5835,  -2.3203,   5.3840,   1.6055,\n",
      "           5.7002,  -3.8691,   8.5255],\n",
      "        [ 16.2918, -10.4379,   4.8451,   2.0660,  -3.0274,   7.0246,   2.0947,\n",
      "           7.4371,  -5.0480,  11.1233],\n",
      "        [ 13.5916,  -8.7079,   4.0421,   1.7236,  -2.5256,   5.8603,   1.7475,\n",
      "           6.2045,  -4.2114,   9.2798],\n",
      "        [  9.9638,  -6.3837,   2.9632,   1.2635,  -1.8515,   4.2961,   1.2811,\n",
      "           4.5485,  -3.0873,   6.8029],\n",
      "        [  0.5353,  -0.3429,   0.1592,   0.0679,  -0.0995,   0.2308,   0.0688,\n",
      "           0.2444,  -0.1659,   0.3655]])\n",
      "tensor([-77.8280,  -5.6396,  45.1962,  17.0367,  48.4618,   2.0711, -39.8674,\n",
      "        -27.1348,  21.9251,  10.1709])\n"
     ]
    }
   ],
   "source": [
    "loss = torch.mean(mse_loss_function(y_pred, y))       # MSE Loss 계산! -> 10개 관측치에 대하여 평균을 취해줌!\n",
    "print(\"MSE loss: \", loss)              # 관측치마다 계산된 loss의 평균 값\n",
    "\n",
    "loss.backward() # backward 가능\n",
    "\n",
    "print(w1.grad.squeeze()[:5,])\n",
    "print(w2.grad.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zero_grad()\n",
    "- backward를 통해 계산된 gradients는 매 역전파 시 누적됨\n",
    "- 따라서 한 번의 학습이 완료 되면 gradients를 0으로 다시 초기화 해주어야 함 (이전 학습 시 저장된 값들이 다음 학습 시에 간섭을 해서 학습이 망가질 수 있기 때문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(69.9819, grad_fn=<MeanBackward0>) \n",
      "\n",
      "First call\n",
      "tensor([-155.6561,  -11.2792,   90.3925,   34.0733,   96.9235,    4.1421,\n",
      "         -79.7347,  -54.2695,   43.8502,   20.3419])\n",
      "\n",
      "Second call\n",
      "tensor([-233.4841,  -16.9188,  135.5887,   51.1100,  145.3853,    6.2132,\n",
      "        -119.6021,  -81.4043,   65.7753,   30.5128])\n",
      "\n",
      "Call after zeroing gradients\n",
      "tensor([-77.8280,  -5.6396,  45.1962,  17.0367,  48.4618,   2.0711, -39.8674,\n",
      "        -27.1348,  21.9251,  10.1709])\n"
     ]
    }
   ],
   "source": [
    "# backward를 통해 계산된 gradient는 backward를 할 때마다 누적\n",
    "# 따라서 backward를 한 번 한 뒤, 초기화가 필요\n",
    "\n",
    "loss = torch.mean(mse_loss_function(y_pred, y))   # loss, -> loss function이 매개변수에 대해 어떻게 변하는지를 보고자 함. #### 미분함수 f'(x) = 2(x+1)\n",
    "print('Loss: ', loss, '\\n')\n",
    "loss.backward(retain_graph=True)   # backward (cf. Should specify retain_graph=True if you need to backward through the graph a second time)\n",
    "\n",
    "print(f\"First call\\n{w2.grad.squeeze()}\")   # w2의 grad 임시 확인\n",
    "loss.backward(retain_graph=True)\n",
    "\n",
    "print(f\"\\nSecond call\\n{w2.grad.squeeze()}\")\n",
    "w2.grad.zero_()   ###### zero gradient #######\n",
    "loss.backward(retain_graph=True)\n",
    "print(f\"\\nCall after zeroing gradients\\n{w2.grad.squeeze()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stop autograd (test)\n",
    "- 모델의 성능을 평가하는 Test (Inference) 단계에서는 역전파(backward)를 통한 파라미터 업데이트가 불필요\n",
    "- Test 단계 외에도 backward를 위한 computation graph를 만드는 것은 연산 시간을 늘리기에, 필요없는 구간에서는 자동 미분을 끔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  7.7196,   9.6569, -10.3071,   5.7333,  -1.8043,   7.0981, -13.0786,\n",
      "         -5.1891,  -7.5665,   8.6904], grad_fn=<SqueezeBackward0>)\n",
      "tensor(69.9819)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    loss = torch.mean(mse_loss_function(y_pred, y))\n",
    "\n",
    "print(y_pred.squeeze())\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
